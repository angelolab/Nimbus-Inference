{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nimbus Interactive Viewer\n",
    "This notebook let's you view the the Pan-Multiplex dataset and it's gold-standard annottions in an interactive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from nimbus_inference.nimbus import Nimbus, prep_naming_convention\n",
    "from nimbus_inference.utils import MultiplexDataset, InteractiveDataset\n",
    "from nimbus_inference.viewer_widget import NimbusInteractiveGTViewer\n",
    "from nimbus_inference.example_dataset import download_and_unpack_gold_standard\n",
    "from alpineer import io_utils\n",
    "import pandas as pd\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Download the Pan-Multiplex gold-standard subset\n",
    "The Pan-M dataset is a large dataset with over 100GB in images. To make it easier to view the annotations, we have created a subset of the dataset that only contains the FoVs that were manually annotated by experts. You can download this subset by running the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where you want to save the dataset\n",
    "save_dir = \"../data\"\n",
    "\n",
    "# Call the function to download and unpack the dataset\n",
    "download_and_unpack_gold_standard(save_dir=save_dir, overwrite_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = os.path.normpath(\"../data/gold_standard_labelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Load Pan-Multiplex dataset and annotations via the `MultiplexDataset` class\n",
    "Next we will use the `MultiplexDataset` class to load the dataset and annotations. Then, the individual datasets are put into the `InteractiveDataset`, which allows for using the `NimbusInteractiveGTViewer` for interactive viewing of the data and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv(os.path.join(base_dir, \"gold_standard_groundtruth.csv\"))\n",
    "\n",
    "dataset_dict = {}\n",
    "dsets = ['codex_colon', 'mibi_breast', 'mibi_decidua', 'vectra_colon', 'vectra_pancreas']\n",
    "suffixes = ['.ome.tif', '.tiff', '.tif', '.ome.tif', '.ome.tif']\n",
    "\n",
    "for dset, suffix in zip(dsets, suffixes):\n",
    "    # prepare naming convetion\n",
    "    dataset_path = os.path.join(base_dir, dset)\n",
    "    fov_path = os.path.join(dataset_path, \"fovs\")\n",
    "    fov_paths = [os.path.join(fov_path, f) for f in os.listdir(fov_path)]\n",
    "    segmentation_dir = os.path.join(dataset_path, \"masks\")\n",
    "    segmentation_naming_convention = prep_naming_convention(segmentation_dir, approx=True)\n",
    "    # test segmentation_naming_convention\n",
    "    if os.path.exists(segmentation_naming_convention(fov_paths[0])):\n",
    "        print(\"Segmentation data exists for fov 0 and naming convention is correct\")\n",
    "    else:\n",
    "        print(\"Segmentation data does not exist for fov 0 or naming convention is incorrect\")\n",
    "    # initialize MultiplexedDataset objects\n",
    "    dataset = MultiplexDataset(\n",
    "        fov_paths=fov_paths,\n",
    "        suffix=suffix,\n",
    "        include_channels=gt_df[gt_df['dataset'] == dset]['channel'].tolist(),\n",
    "        segmentation_naming_convention=segmentation_naming_convention,\n",
    "        groundtruth_df=gt_df[gt_df['dataset'] == dset],\n",
    "        output_dir=dataset_path,\n",
    "    )\n",
    "    dataset_dict[dset] = dataset\n",
    "\n",
    "datasets = InteractiveDataset(\n",
    "    datasets=dataset_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use the `NimbusInteractiveGTViewer` to explore the dataset and annotations\n",
    "The `NimbusInteractiveGTViewer` class allows you to interactively view the dataset and annotations. You can zoom in and out of the images, pan around, and view the annotations on the right. The annotations are displayed with 100% pixel intensity for positive cells, 30% pixel intensity for ambiguous cells, and 0% pixel intensity for negative cells. Resize the viewer by dragging the triangle in the bottom right corner.\n",
    "\n",
    "To zoom in and out of the images and pan around:\n",
    "\n",
    "1. Click the cross icon on the left to enable image interaction mode.\n",
    "2. To pan, right-click and drag the image.\n",
    "3. To zoom, left-click on the image and drag up to zoom in or drag down to zoom out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viewer = NimbusInteractiveGTViewer(\n",
    "    datasets=datasets,\n",
    "    output_dir=os.path.join(base_dir, \"output\"),\n",
    "    figsize=(10, 5),\n",
    ")\n",
    "viewer.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nimbus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
